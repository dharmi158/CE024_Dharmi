{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CE023_Lab7_2_LogisticReg.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Logistic Regression Tensorflow"],"metadata":{"id":"eKEgpY7qbCzk"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ag5mMRtgaqhV","executionInfo":{"status":"ok","timestamp":1645183097114,"user_tz":-330,"elapsed":3542,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"outputs":[],"source":["from __future__ import absolute_import, division, print_function\n","import tensorflow as tf\n","import numpy as np"]},{"cell_type":"markdown","source":["2 Loading and Preparing the MNIST Data Set"],"metadata":{"id":"BBZoqZe4bPKi"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Convert to float32.\n","\n","x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n","\n","# Flatten images to 1-D vector of 784 features (28*28).\n","num_features=784\n","x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n","\n","# Normalize images value from [0, 255] to [0, 1].\n","\n","x_train, x_test = x_train / 255., x_test / 255."],"metadata":{"id":"QNWtA06_bKsA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4524f31e-c198-42ce-aa58-cc86d10f3b2f","executionInfo":{"status":"ok","timestamp":1645183110448,"user_tz":-330,"elapsed":1511,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["3 Setting Up Hyperparameters and Data Set Parameters"],"metadata":{"id":"uErjaTzJnkQR"}},{"cell_type":"code","source":["# MNIST dataset parameters.\n","num_classes = 10 # 0 to 9 digits\n","num_features = 784 # 28*28\n","# Training parameters.\n","learning_rate = 0.01\n","training_steps = 1000\n","batch_size = 256\n","display_step = 50"],"metadata":{"id":"yZgLTexpnkoU","executionInfo":{"status":"ok","timestamp":1645183125031,"user_tz":-330,"elapsed":512,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["4 Shuffling and Batching the Data"],"metadata":{"id":"RLImadWRnqNl"}},{"cell_type":"code","source":["# Use tf.data API to shuffle and batch data.\n","\n","train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n","train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"],"metadata":{"id":"xbzX5thNnqv5","executionInfo":{"status":"ok","timestamp":1645183131192,"user_tz":-330,"elapsed":504,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["5 Initializing Weights and Biases"],"metadata":{"id":"JhXbGlu4n0XH"}},{"cell_type":"code","source":["# Weight of shape [784, 10], the 28*28 image features, and a total number of classes.\n","W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n","\n","# Bias of shape [10], the total number of classes.\n","b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")"],"metadata":{"id":"ifkNylJHn212","executionInfo":{"status":"ok","timestamp":1645183135301,"user_tz":-330,"elapsed":786,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["6 Defining Logistic Regression and Cost Function"],"metadata":{"id":"haUvGGitoCHC"}},{"cell_type":"code","source":["# Logistic regression (Wx + b).\n","def logistic_regression(x):\n","  # Apply softmax to normalize the logits to a probability distribution.\n","    return tf.nn.softmax(tf.matmul(x, W) + b)\n","\n","# Cross-Entropy loss function\n","def cross_entropy(y_pred, y_true):\n","    # Encode label to a one hot vector.\n","    y_true = tf.one_hot(y_true, depth=num_classes)\n","\n","    # Clip prediction values to avoid log(0) error.\n","    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n","\n","    # Compute cross-entropy.\n","    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))"],"metadata":{"id":"u8AHELqjoCpJ","executionInfo":{"status":"ok","timestamp":1645183140968,"user_tz":-330,"elapsed":792,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["7 Defining Optimizers and Accuracy Metrics"],"metadata":{"id":"nn26nTHfoWC3"}},{"cell_type":"code","source":["# Accuracy metric.\n","def accuracy(y_pred, y_true):\n","\n","# Predicted class is the index of the highest score in prediction vector (i.e. argmax).\n","  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n","  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","# Stochastic gradient descent optimizer.\n","optimizer = tf.optimizers.SGD(learning_rate)"],"metadata":{"id":"Ip4U4im3oWik","executionInfo":{"status":"ok","timestamp":1645183146594,"user_tz":-330,"elapsed":528,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["8 Optimization Process and Updating Weights and Biases"],"metadata":{"id":"5zyxBfJ3o9pZ"}},{"cell_type":"code","source":["# Optimization process.\n","def run_optimization(x, y):\n","\n","# Wrap computation inside a GradientTape for automatic differentiation.\n","    with tf.GradientTape() as g:\n","        pred = logistic_regression(x)\n","        loss = cross_entropy(pred, y)\n","\n","    # Compute gradients.\n","    gradients = g.gradient(loss, [W, b])\n","\n","  \n","\n","    # Update W and b following gradients.\n","    optimizer.apply_gradients(zip(gradients, [W, b]))"],"metadata":{"id":"YymPnJXQo-BF","executionInfo":{"status":"ok","timestamp":1645183152165,"user_tz":-330,"elapsed":5,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["9 The Training Loop"],"metadata":{"id":"PRZylO-lpJ7a"}},{"cell_type":"code","source":["# Run training for the given number of steps.\n","for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n","\n","    # Run the optimization to update W and b values.\n","    run_optimization(batch_x, batch_y)\n","    if step % display_step == 0:\n","        pred = logistic_regression(batch_x)\n","        loss = cross_entropy(pred, batch_y)\n","        acc = accuracy(pred, batch_y)\n","        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wR2s4_StpKde","outputId":"60ed003e-c2a8-403f-d78c-8ad5e4134cbf","executionInfo":{"status":"ok","timestamp":1645183164583,"user_tz":-330,"elapsed":7081,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["step: 50, loss: 83.917328, accuracy: 0.898438\n","step: 100, loss: 122.090408, accuracy: 0.855469\n","step: 150, loss: 83.060532, accuracy: 0.917969\n","step: 200, loss: 60.105988, accuracy: 0.921875\n","step: 250, loss: 95.764908, accuracy: 0.875000\n","step: 300, loss: 190.718384, accuracy: 0.843750\n","step: 350, loss: 82.869995, accuracy: 0.937500\n","step: 400, loss: 457.332642, accuracy: 0.804688\n","step: 450, loss: 57.373962, accuracy: 0.941406\n","step: 500, loss: 59.072987, accuracy: 0.914062\n","step: 550, loss: 65.845634, accuracy: 0.933594\n","step: 600, loss: 333.008728, accuracy: 0.722656\n","step: 650, loss: 91.284149, accuracy: 0.921875\n","step: 700, loss: 36.801952, accuracy: 0.957031\n","step: 750, loss: 44.390068, accuracy: 0.941406\n","step: 800, loss: 71.033966, accuracy: 0.921875\n","step: 850, loss: 57.851971, accuracy: 0.929688\n","step: 900, loss: 64.505096, accuracy: 0.937500\n","step: 950, loss: 91.217461, accuracy: 0.941406\n","step: 1000, loss: 45.566856, accuracy: 0.949219\n"]}]},{"cell_type":"markdown","source":["10 Testing Model Accuracy Using the Test Data"],"metadata":{"id":"DQD-xHUnplRS"}},{"cell_type":"code","source":["# Test model on validation set.\n","pred = logistic_regression(x_test)\n","print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sB1-rAv6pmGF","outputId":"efec873e-72e0-4fde-ae42-6ccf2ad6b714","executionInfo":{"status":"ok","timestamp":1645183171747,"user_tz":-330,"elapsed":797,"user":{"displayName":"CE023_Bhavin_Chavda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01873417777669950613"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.920900\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"2vOrXiGEjvZ4"},"execution_count":null,"outputs":[]}]}